{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LossFunctions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinaj-gupta/Loss-Function-Summary/blob/master/LossFunctions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aQExkhRzGql",
        "colab_type": "text"
      },
      "source": [
        "#Cost Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_cFjZZ6-7ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "y_true = np.array([3, -0.5, 2, 7])  # Ground truth (correct) target values vector\n",
        "y_pred = np.array([2.5, -0.3, 2, 8])  # Estimated target values vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpNw96Ek1JUF",
        "colab_type": "text"
      },
      "source": [
        "### MSE  (Mean Squared Error) or L2 Loss\n",
        "MSE is the average of the squared error that is used as the loss function for least squares regression:\n",
        "\n",
        "# ![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Gl34gJ2Ogz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSE(yHat, y):\n",
        "    return np.sum((yHat - y)**2) / y.size \n",
        "  \n",
        "mean_square_error = MSE(y_pred,y_true)\n",
        "print(mean_square_error) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7LvgwEe2hBr",
        "colab_type": "text"
      },
      "source": [
        "### RMSE (Root Mean Square Error)\n",
        "\n",
        "Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\n",
        "\n",
        "![alt text](http://statweb.stanford.edu/~susan/courses/s60/split/img29.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qXGa0Vd3dXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RMSE(yHat, y):\n",
        "    return np.sqrt(np.sum((yHat - y)**2) / y.size)\n",
        "  \n",
        "root_mean_square_error = RMSE(y_pred,y_true)\n",
        "print(root_mean_square_error)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtcviRRK4Pvb",
        "colab_type": "text"
      },
      "source": [
        "### MAE (Mean Absolute Error) or L1 Loss\n",
        "\n",
        "Mean Absolute Error, also known as MAE, is one of the many metrics for summarizing and assessing the quality of a machine learning model.\n",
        "\n",
        "MAE = Average of All absolute errors\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/3ef87b78a9af65e308cf4aa9acf6f203efbdeded)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC2qVU_J5Q5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MAE(yHat, y):\n",
        "    return np.sum(np.absolute(yHat - y))/y.size\n",
        "  \n",
        "mean_absolute_error = MAE(y_pred,y_true)\n",
        "print(mean_absolute_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseDi1y85xmZ",
        "colab_type": "text"
      },
      "source": [
        "### MAPE (Mean Absolute Percentage Error)\n",
        "\n",
        "The MAPE (Mean Absolute Percent Error) measures the size of the error in percentage terms. It is calculated as the average of the unsigned percentage error\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/4cf2158513b0345211300fe585cc88a05488b451)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjPeK9dc6XVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MAPE(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "  \n",
        "mean_absolute_percentage_error = MAPE(y_pred,y_true)\n",
        "print(mean_absolute_percentage_error)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9KdllUoCkO9",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy Loss\n",
        "\n",
        "This is the most common setting for classification problems. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/80f87a71d3a616a0939f5360cec24d702d2593a2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grp5nUP7CqCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66adda34-6c2c-4ac4-edff-3ad41127a011"
      },
      "source": [
        "def CE(predictions, targets, epsilon=1e-10):\n",
        "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
        "    N = predictions.shape[0]\n",
        "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N\n",
        "    return ce_loss\n",
        "  \n",
        "cross_entropy = CE(y_pred,y_true)\n",
        "print(cross_entropy)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.4391444326775327\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}